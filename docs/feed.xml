<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://jkschin.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://jkschin.com/" rel="alternate" type="text/html" hreflang="en" /><updated>2024-08-01T14:01:24-04:00</updated><id>https://jkschin.com/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">Deciphering src_key_padding_mask</title><link href="https://jkschin.com/blog/2024/src-key-padding-mask/" rel="alternate" type="text/html" title="Deciphering src_key_padding_mask" /><published>2024-08-01T11:59:00-04:00</published><updated>2024-08-01T11:59:00-04:00</updated><id>https://jkschin.com/blog/2024/src-key-padding-mask</id><content type="html" xml:base="https://jkschin.com/blog/2024/src-key-padding-mask/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>How do you know your ML model is learning correctly?
After all, given enough capacity, it could probably fit any input you give it.
You can have a low loss and decently correct outputs, but is your model actually correct?
I was checking my code recently and decided to dive deep into how <code class="language-plaintext highlighter-rouge">src_key_padding_mask</code> in PyTorch Transformers work and check if my outputs are actually correct.</p>

<h2 id="padding-in-transformers">Padding in Transformers</h2>

<p>In most Transformer models, padding is necessary as your inputs may have a different size.
For example, a given sentence could be 100 tokens long, but another sentence is 101 tokens long.
For efficient batch training, it is necessary to pad these inputs.
Of course, one can argue that the additional padding would cause inefficiency, but that’s really a separate point for another day and in general you would still pad.</p>

<p>In the code example below, we specifically test the <code class="language-plaintext highlighter-rouge">TransformerEncoder</code>.
It is also relatively easy to think of a test that would convince us that it is doing the right thing.
Consider an input of shape <code class="language-plaintext highlighter-rouge">(32, 10, 512)</code>, which represent the batch size, sequence length and dimension respectively.
Further consider how perhaps only the first two tokens are relevant, and the other 8 are simply padded tokens.
You would expect that this input, together with a correctly constructed <code class="language-plaintext highlighter-rouge">src_key_padding_mask</code> would yield a relevant output (<code class="language-plaintext highlighter-rouge">output[:, :2, :]</code>), with the other outputs being irrelevant (<code class="language-plaintext highlighter-rouge">output[:, 2:, :]</code>).
Finally, if you put into this same Transformer <code class="language-plaintext highlighter-rouge">input[:, :2, :]</code>, the output should be identical to <code class="language-plaintext highlighter-rouge">output[:, :2, :]</code> <strong>with the</strong> <code class="language-plaintext highlighter-rouge">src_key_padding_mask</code>.
Put simply, self-attention on the two relevant tokens is equivalent to self-attention on all ten tokens with the correct <code class="language-plaintext highlighter-rouge">src_key_padding_mask</code>.
With this intuition, I worked with Google Gemini to generate some starter code to test this, and it’s correct!</p>

<h2 id="code">Code</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="c1"># Test the model
</span>
<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span> <span class="c1"># Create input data (bsz x seq_len x dim)
</span>    <span class="n">bsz</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">512</span>
    <span class="n">input_data</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="n">bsz</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>

    <span class="c1"># Initialize model
</span>    <span class="n">encoder_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">TransformerEncoderLayer</span><span class="p">(</span>
        <span class="n">d_model</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
        <span class="n">nhead</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>  <span class="c1"># (bsz, seq_len, dim) format
</span>        <span class="n">dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>  <span class="c1"># ensures more determinism
</span>    <span class="p">)</span>
    <span class="n">transformer_encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">encoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">pad_idx</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">):</span>
        <span class="c1"># Create the src_key_padding_mask
</span>        <span class="n">src_key_padding_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">bsz</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">src_key_padding_mask</span><span class="p">[:,</span> <span class="n">pad_idx</span><span class="p">:]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">True</span>  <span class="c1"># True indices are the masked positions
</span>        <span class="p">)</span>

        <span class="c1"># Forward pass
</span>        <span class="n">output</span> <span class="o">=</span> <span class="n">input_data</span>
        <span class="n">trunc</span> <span class="o">=</span> <span class="n">input_data</span><span class="p">[:,</span> <span class="p">:</span><span class="n">pad_idx</span><span class="p">,</span> <span class="p">:]</span>
        <span class="k">for</span> <span class="n">layer_idx</span><span class="p">,</span> <span class="n">mod</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">transformer_encoder</span><span class="p">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="n">output</span> <span class="o">=</span> <span class="nf">mod</span><span class="p">(</span>
                <span class="n">output</span><span class="p">,</span> <span class="n">src_key_padding_mask</span><span class="o">=</span><span class="n">src_key_padding_mask</span>
            <span class="p">)</span>  <span class="c1"># input data with src_key_padding_mask
</span>            <span class="n">trunc</span> <span class="o">=</span> <span class="nf">mod</span><span class="p">(</span><span class="n">trunc</span><span class="p">)</span>  <span class="c1"># truncated relevant input data
</span>
        <span class="c1"># Observe how the truncated output is identical to the normal output with src_key_padding_mask
</span>        <span class="c1"># indicating that the padding is correctly handled
</span>        <span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="nf">all</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">isclose</span><span class="p">(</span><span class="n">trunc</span><span class="p">,</span> <span class="n">output</span><span class="p">[:,</span> <span class="p">:</span><span class="n">pad_idx</span><span class="p">,</span> <span class="p">:],</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">))</span>

    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">All test cases passed!</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="code" /><summary type="html"><![CDATA[A deep dive into src_key_padding_mask and how to check for correctness.]]></summary></entry><entry><title type="html">Hypothesis Driven Mindset and First Principles Thinking</title><link href="https://jkschin.com/blog/2024/thinking-styles/" rel="alternate" type="text/html" title="Hypothesis Driven Mindset and First Principles Thinking" /><published>2024-02-04T10:59:00-05:00</published><updated>2024-02-04T10:59:00-05:00</updated><id>https://jkschin.com/blog/2024/thinking-styles</id><content type="html" xml:base="https://jkschin.com/blog/2024/thinking-styles/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>I’m working on a startup in MIT Sandbox and signed up for an expert session recently.
As we were nearing the end of the call, I asked about the unknown unknowns when starting a company as these are risks that one has to be mitigate.
Put another way, you don’t know what you don’t know and thus can be easily caught off guard.
He mentioned three points, of which the one I want to dive deep on here is the hypothesis driven mindset.
This got me thinking about how I think once again.
I thought about how a given problem that one needs to solve can be approached from two angles: a hypothesis driven mindset and first principles thinking.
Some might call this inductive reasoning and deductive reasoning, or bottom-up and top-down.
I personally don’t like those definitions - you have to memorize those definitions and what’s bottom-up to you may be top-down to someone else.
I have been looking into some finance applications recently and thus will structure the examples around finance.</p>

<h2 id="hypothesis-driven-mindset">Hypothesis Driven Mindset</h2>

<p>When studying for a class, it is often useful to do many practice questions - the question is sort of the hypothesis in this case.
You are given a question and have to dive deep into the textbooks, the lectures, the notes, and figure out principles that can help you solve the problem.
In the context of finance, one question you might ask yourself would be: What trades can I make this week?
Well, that’s a really broad question, and those who have done management consulting interviews would be familiar with these types of questions and you have to “drill down” and not “boil the ocean” (I promise this is only used once in this post!).
So you might start drawing a tree and asking yourself lots of questions.
You think about what might affect trades this week - earnings announcements, federal reserve meetings, inflation data being released, job market reports, etc.
You think about what kind of risk you’re willing to take.
You think about any downside protections you might want to have.
The list goes on.
Eventually, you arrive at a trade that you can make and you go through that strategy thoroughly before making that trade.</p>

<h2 id="first-principles-thinking">First Principles Thinking</h2>

<p>I learnt first principles thinking from my mother as she taught that to me from a young age.
I’m not sure what the prevailing definition of it is now - I am not here to offer one in any case.
Again, in the context of finance, a first principles question you might ask yourself would be: What return distribution does a given stock follow?
I don’t actually know the answer to this, and I can imagine the answer is really complex.
I have brief exposure to this, and I do know that there was some random walk paper a long time ago (40, 50 years maybe?).
Ultimately, it’s a really hard question and the answer is probably “it depends”.
In some contexts, it might be a random walk.
It’s also probably a nonstationary process.
The list of technical terms you can use goes on and on.
The value of answering a question like that, is that you get to understand the underlying processes of something deeply.</p>

<h2 id="application-to-life-in-general">Application to Life in General</h2>

<p>As you would probably have guessed, you can’t just stick to one mindset and apply it religiously.
You have to use a mix of both.
First principles thinking enables you to acquire a set of tools.
A hypothesis driven mindset gives you opportunities to explore questions and potentially leverage these tools.
The important catch here is to understand the tools you have in your toolbox.
When you’re in the moment and deep in a problem, you might forget that you have a certain tool in your toolbox.
For example, when you are deep into coding something from scratch, you might forget that you saw a framework or codebase 6 months ago that could be helpful.
Or when you’re cooking something on the stove, you grab the nearest tool that does the job, but there might be a better tool in the drawer that you forgot was there.
Or you may realize that you don’t have the tool and you need to acquire it!
It can be useful to take a step back sometimes and try and meet in the middle through both forms of thinking.</p>

<p>While these are tools for thinking, I missed out the most important motivating factor - what are you doing this for?
If you’re cooking, it’s probably to have some delicious food.
If you’re coding something, it’s probably to build good software.
If you’re writing a paper, it’s probably to propose a new method and publish a paper.
The framework of thinking helps you to achieve a goal.
I intentionally did not put this at the start, as that’s probably implicit and only worth mentioning at this point.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I’ve been writing more on thinking about how to think recently.
I already somewhat apply this to my research, but I will be doing this more intentionally.
Specifically, I start with a hypothesis: Can I use X to solve Y?
I then dive deeper into the relevant papers, and try and confirm or disprove this hypothesis.
At the same time, while diving into the process, I try and recall the mathematical tools that I have learnt, and also how to implement the code.
More importantly, I need to think about how to structure the paper, run the experiments and present the results such that the paper will have a higher chance of getting accepted.
I think it can be useful to start with the goal and draw a mind map from there.
Perhaps I will try this.</p>]]></content><author><name></name></author><category term="personal" /><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">PhD Reflection (and hopefully advice to prospective students)</title><link href="https://jkschin.com/blog/2024/phd-reflection/" rel="alternate" type="text/html" title="PhD Reflection (and hopefully advice to prospective students)" /><published>2024-01-29T10:59:00-05:00</published><updated>2024-01-29T10:59:00-05:00</updated><id>https://jkschin.com/blog/2024/phd-reflection</id><content type="html" xml:base="https://jkschin.com/blog/2024/phd-reflection/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>It’s the final week of the Independent Activities Period (IAP) at MIT and I attended an event titled “IAP 2024: Expanding Horizons in Computing”.
I consciously chose not to link this page as it’s definitely going to become stale one day and I do not want to have to deal with that.
I have other reflections on the talks, but I want to highlight the importance of stepping back from research once in awhile to see what’s out there.
In particular, I chose to attend the talks on Computer Security.
I learnt about Fully Homomorphic Encryption, amongst other things.
However, my biggest takeaway was searching for a speaker (Henry Corrigan-Gibbs) and coming across his <a href="https://people.csail.mit.edu/henrycg/">personal page</a>.
Under the advice section on CG’s page, I saw three articles from
<a href="https://www.cs.cmu.edu/~mblum/research/pdf/grad.html">Manuel Blum</a>,
<a href="https://www.cs.cmu.edu/~harchol/gradschooltalk.pdf">Mor Harchol-Balter</a> and
<a href="https://www.cs.virginia.edu/~robins/YouAndYourResearch.html">Richard Hamming</a> and read them (technically the one from Hamming is a transcribed lecture).
I started by browsing the article from Manuel Blum and he mentioned that you should <em>always</em> be writing.
I immediately took out a pen and paper and started to write some thoughts and then decided to write a proper reflection as I’m currently midway (approximately) through my PhD (I’m all done with classes and finished my Thesis Proposal meeting).
This reflection serves to synthesize my thoughts and hopefully inform prospective students on whether or not they should pursue a PhD.
In addition, I write some thoughts on how to approach research.
Nothing beats reading those three articles yourself though!</p>

<h2 id="why-do-a-phd">Why do a PhD?</h2>

<p>To answer that question, I’d have to start with a brief history of my life trajectory.
I graduated in 2015 with a degree in computer science.
Unsure of what to do next, I joined a government research lab and did applied research.
I was interested in the research problems and started reading many papers from Computer Vision (CV) conferences like CVPR, ICCV and ECCV.
This was also the start of the deep learning revolution and AlexNet was only published three years ago.
I still recall using Caffe and some other weird deep learning frameworks - those were really hard to use.
Seeing an opportunity to commercialize CV, I joined an accelerator to start a CV company.
That didn’t work out and I joined Palantir in 2017.
Even at Palantir as a software engineer, I dug into the code, tried to fully understand the frameworks, the architecture decisions, etc.
I read many textbooks on the many flights that I was on.
I found myself attracted to hard problems and diving deep into something and fully understanding it.
Mor Harchol-Balter’s comment resonates with me:</p>

<blockquote>
  <p><strong>There’s also the joy of doing it right</strong>. In a company, the aim is to
get a working product and ship it out quickly. In research, you can take your time
and plan out your project so that you are proud to defend every one of your design
decisions. Research is not about simple heuristics or quick hacks. Many people
also relish the joy of being the authority on an area and of having their work read
and cited by others.
– <cite>Mor Harchol-Balter</cite></p>
</blockquote>

<p>Indeed, there is joy in itself of having the freedom to plan something, execute it, and doing it right within the set of resource constrants you’re given.
I say this, as even within a PhD, you do not have infinite time.
You have more time to dive deeper into something when compared to a commercial environment, but time and money is still finite.
I guess while at Palantir, I wanted to do a PhD at the back of my mind and do more work in deep learning (commonly called AI nowadays but I’m still old school).
Well, I’m at MIT for a PhD now, and the rest is history.
I’m right about midway through my PhD and I have finished all my required classes.
I do enjoy taking classes, and would continue taking perhaps one class each semester.
However, it would probably not be optimal to do that, and Mor Harchol-Balter discusses it more in her document.
Coming from industry, I thought how she described a PhD was largely accurate:</p>

<blockquote>
  <p>The Ph.D. is a tremendous opportunity. You get to pick an advisor in any research area you like and then you get to do research in that area, receive mentoring,
<strong>think deeply on problems</strong>, publish papers, become famous, while paying zero tuition for 6 years and receiving a salary.
– <cite>Mor Harchol-Balter</cite></p>
</blockquote>

<p>So what’s next after my PhD?
I haven’t thought it out thoroughly, and this is bound to change.
I know I do want to build a product or commercialize my research and start a company.
I am also keen on research and AI is really an exciting field now.
In particular, the recent papers on <a href="https://deepmind.google/discover/blog/millions-of-new-materials-discovered-with-deep-learning/">discovering new materials from DeepMind</a> is really cool.
Having a PhD gives me the option of doing research upon graduation.</p>

<blockquote>
  <p>When making a decision about the next 6 years of your life, it’s good to stop and
think about what you might do when you finish. Most students upon completing a
Ph.D. either go into academia (research university or teaching school) and become
a professor, or they go to a research lab. Some people never do research again after
completing a Ph.D. For such people, the Ph.D. was largely a waste of time.
– <cite>Mor Harchol-Balter</cite></p>
</blockquote>

<p>If I don’t do research after graduation, would it really largely be a waste of time?
It was a great intellectual exercise and I got to dive deeper into some of the topics that I am interested in.
Put another way, this was probably my only chance of doing it.
I don’t think I would do it at an older age as I would have other priorities then.</p>

<h2 id="how-should-you-approach-research">How should you approach research?</h2>

<p>I read The Power of Habit by Charles Duhigg last year.
A key insight I got was that if you want to shape your mind to do X instead of Y (where X is the optimal thing to do) when a certain cue happens, you can write down exactly what you will do when you face that cue and it will be much easier to tune your mind to the good habit.
Why does this matter?
Well, a lot of times in your PhD, you will be tempted to just read for the sake of reading, with no clear goal in sight.
Or when you are stuck on a problem for 1 hour and you finally have the Eureka moment - you decide to take a break and come back to it 15 minutes later, only to spend another 30 minutes trying to figure out how you got to the Eureka moment.
The optimal thing to do there is simply to just sit for another 5 to 10 minutes, write down your thoughts, and then take a break.
If all this sounds familiar to you, then the next few sections will be extremely relevant.
The next few sections will be structured around cues and how to handle them - practical tips that you can directly execute.</p>

<p><strong>It’s the start of a new semester. You’re in this exciting new class. You look at all the readings and the textbooks, and you decide to read textbooks end to end.</strong></p>

<p>I love reading.
In particular, I love reading a textbook end-to-end.
With infinite time, it’s possibly effective, as you can read it over and over again and you glean new insight each time you read.
However, I quickly found that sometimes it’s important to just zoom into a concept, write some math and code, and understand that concept really well.
I was reminded of this and Manuel Blum put it really well:</p>

<blockquote>
  <p>Books are not scrolls.
Scrolls must be read like the Torah from one end to the other.
Books are random access – a great innovation over scrolls.
Make use of this innovation! Do NOT feel obliged to read a book from beginning to end.
Permit yourself to open a book and start reading from anywhere.
In the case of mathematics or physics or anything especially hard, try to find something anything that you can understand.
Read what you can.
Write in the margins. (You know how useful that can be.)
Next time you come back to that book, you’ll be able to read more.
You can gradually learn extraordinarily hard things this way.
– <cite>Manuel Blum</cite></p>
</blockquote>

<p>Clearly, the inference one can make about this is to read papers from one end to the other as it is a scroll.
How should one read a paper then?
For that, I refer the reader to <a href="https://www.youtube.com/watch?v=733m6qBH-jI">a video from Andrew Ng</a>.
It is also important to note here, some wise advice from Richard Hamming:</p>

<blockquote>
  <p>There was a fellow at Bell Labs, a very, very, smart guy. He was always in the library; he read everything. If you wanted references, you went to him and he gave you all kinds of references. But in the middle of forming these theories, I formed a proposition: there would be no effect named after him in the long run. He is now retired from Bell Labs and is an Adjunct Professor. He was very valuable; I’m not questioning that. He wrote some very good Physical Review articles; but there’s no effect named after him because he read too much. If you read all the time what other people have done you will think the way they thought. If you want to think new thoughts that are different, then do what a lot of creative people do - get the problem reasonably clear and then refuse to look at any answers until you’ve thought the problem through carefully how you would do it, how you could slightly change the problem to be the correct one. So yes, you need to keep up. You need to keep up more to find out what the problems are than to read to find the solutions. The reading is necessary to know what is going on and what is possible. But reading to get the solutions does not seem to be the way to do great research. So I’ll give you two answers. <strong>You read; but it is not the amount, it is the way you read that counts.</strong>
– <cite>Richard Hamming</cite></p>
</blockquote>

<p><strong>You now know the techniques of reading. You buy the physical textbook or you download the PDF onto your laptop or you are reading a paper. You wake up early in the morning and go to a cafe. You first start scrolling social media, and then open up your textbook or laptop. You resist reading the introduction of the textbook and focus on key chapters, or you read the paper optimally. You read a few lines, and sip a coffee, and this repeats. Half an hour later, you have the ideas all in your head. Three days later, you vaguely recall the ideas but can’t fully communicate what the concept is.</strong></p>

<p>This is a situation that happens to me often.
I know the ideas - it’s in my head.
However, it’s so hard to write it down in text.
I find myself referring back to the original paper when writing it down.
Over the years of my PhD, I found that taking out a writing pad to sketch out some ideas helps.
In fact, directly synthesizing your thoughts and writing a short literature review of it or a short blog post about it would help greatly when you’re assembling the final paper.
This can significantly improve your efficiency.
Do you have to write this for every single paper you browse or read?
Probably not.
If there’s a good chance you’re going to cite it or use the concepts in your work, then it could be worth writing a short document on it.
Again, the wisdom of Manuel Blum shines here:</p>

<blockquote>
  <p>Consider writing what you read as you read it.
This is especially true if you’re intent on reading something hard.
– <cite>Manuel Blum</cite></p>
</blockquote>

<p>and here:</p>

<blockquote>
  <p>You are all computer scientists.
You know what FINITE AUTOMATA can do.
You know what TURING MACHINES can do.
For example, Finite Automata can add but not multiply.
Turing Machines can compute any computable function.
Turing machines are incredibly more powerful than Finite Automata.
Yet the only difference between a FA and a TM is that
the TM, unlike the FA, has paper and pencil.
Think about it.
It tells you something about the power of writing.
Without writing, you are reduced to a finite automaton.
With writing you have the extraordinary power of a Turing machine.
– <cite>Manuel Blum</cite></p>
</blockquote>

<p><strong>We now have a framework of reading and writing down our ideas. You’ve also probably heard (I don’t know who first said this) of how choosing the right problem gets you 50% (or some X%) of the way there. What kind of problems should you work on?</strong></p>

<p>Regardless of whether or not you intend to go into academia or industry, you want to do impressive work.
After all, what you write and publish will be on the internet <em>forever</em>.
You would want it to be something you’re proud of - right?
Of course, you can choose the hardest problems in the world to solve, like teleportation or time travel (see below), but you’re never going to get a PhD from that (at least as of writing, I don’t see how this is remotely possible).
Richard Hamming succinctly puts it:</p>

<blockquote>
  <p>If you do not work on an important problem, it’s unlikely you’ll do important work. It’s perfectly obvious. Great scientists have thought through, in a careful way, a number of important problems in their field, and they keep an eye on wondering how to attack them. Let me warn you, `important problem’ must be phrased carefully. The three outstanding problems in physics, in a certain sense, were never worked on while I was at Bell Labs. By important I mean guaranteed a Nobel Prize and any sum of money you want to mention. We didn’t work on (1) time travel, (2) teleportation, and (3) antigravity. They are not important problems because we do not have an attack. It’s not the consequence that makes a problem important, it is that you have a reasonable attack. That is what makes a problem important.
– <cite>Richard Hamming</cite></p>
</blockquote>

<p><strong>You now have decided on a problem, and also a reasonable attack. But what does a reasonable attack mean? What if you get stuck?</strong></p>

<p>After reading tons of papers, you get a sense of the field and see some gaps that you can plug.
You have it in your head, or perhaps written down, a strategy to attack the problem.
Inevitably, you will face bumps along the way and get stuck on a step in your strategy.
This could be anything from making a wrong assumption about something, acquiring new information and realizing you were wrong, and so on.
Whenever I get stuck, I find myself going outside for a walk and thinking in my head.
I get myself unstuck and I end up not writing down the steps to get unstuck at times, and I have to repeat this process.
This goes back to the earlier point of Manuel Blum earlier and writing - always be writing.
In fact, I would say that <em>writing</em> and <em>typing</em> is fundamentally different.
I can type faster than I write (most do), and I can easily do a brain dump of whatever is in my head.
However, the benefit of writing is that you <em>cannot</em> write as fast - your brain is forced to be efficient and synthesizes the most important things, which in itself could be valuable.
The importance of writing might be the <strong>side benefit of synthesis</strong>.
I found that when I do a typing brain dump, I have to revisit it and synthesize it.
More importantly, the reason why I am typing all this, is that I am doing some form of meta thinking about my processes of typing and writing - I am thinking about how I think.
When you are stuck, think about how you’re thinking.
Why are you thinking this way?
Do other people think this way?
Is there someone else that thinks differently and you can learn from her?
As Manuel Blum puts it:</p>

<blockquote>
  <p>There will come a time when you work on a problem long and hard but UNsuccessfully :(
And then you learn that someone else found a solution.
See this as the GREAT opportunity it is to learn something important.
Don’t let it pass you by.
Ask yourself: “How SHOULD I have been thinking to solve that problem?”
I have found that doing so is a powerful exercise.
Danny Sleator tells me that BOB FLOYD independently recommended exactly this exercise to his students.
He would lead them into asking themselves:
“How COULD I have led myself to that answer?”
Take the time to think it through.
It’s worth it.
– <cite>Manuel Blum</cite></p>
</blockquote>

<p>PhD students are obsessed with thinking about the problem and finding solutions.
However, very few spend time thinking about how they are thinking, and this is quite important.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I have more to discuss, but I think it is a good time to take a pause here.
We discussed why you should do a PhD and if you have decided on doing one, how you should approach research in terms of reading, finding an important problem and also getting yourself unstuck.
Nothing beats reading the articles themselves, and I probably will re-read them at some point.
My PhD involves writing quite a bit of code, and I do want to write an actual tactical plan on how to execute a research paper, but I will leave this for another post day and keep this focused.</p>]]></content><author><name></name></author><category term="personal" /><summary type="html"><![CDATA[Introduction]]></summary></entry><entry><title type="html">Intricacies of nn.CrossEntropyLoss Ignore Index and Gradients</title><link href="https://jkschin.com/blog/2023/cross-entropy-loss-ignore-index/" rel="alternate" type="text/html" title="Intricacies of nn.CrossEntropyLoss Ignore Index and Gradients" /><published>2023-05-25T11:59:00-04:00</published><updated>2023-05-25T11:59:00-04:00</updated><id>https://jkschin.com/blog/2023/cross-entropy-loss-ignore-index</id><content type="html" xml:base="https://jkschin.com/blog/2023/cross-entropy-loss-ignore-index/"><![CDATA[<h2 id="introduction">Introduction</h2>

<p>In machine learning, PyTorch’s <code class="language-plaintext highlighter-rouge">nn.CrossEntropyLoss</code> is an often-utilized function.
It combines <code class="language-plaintext highlighter-rouge">nn.LogSoftmax()</code> and <code class="language-plaintext highlighter-rouge">nn.NLLLoss()</code> in one single class to compute the cross-entropy loss between the predicted and actual labels.
The CrossEntropyLoss function offers an optional parameter called <code class="language-plaintext highlighter-rouge">ignore_index</code> that can be used to ignore the loss contribution from some specific classes and is widely used in NLP, where padding of a sequence is necessary.
This post delves into the intricacies of this mechanism and how it affects gradients in backpropagation.
I was using <code class="language-plaintext highlighter-rouge">ignore_index</code> and ran into an issue with <code class="language-plaintext highlighter-rouge">nan</code> values after the first optimization step and had to dive deeper into the issue.
As with all code debugging nowadays (and writing), I used ChatGPT to assist me in writing this post.</p>

<h2 id="context">Context</h2>

<p>I was training a GPT based model and the final output is postprocessed with a mask.
In a classic GPT language model, you simply softmax over the vocabulary and it outputs the relevant token.
However, I wanted to mask out some parts of the vocabulary and thus created a mask with <code class="language-plaintext highlighter-rouge">-inf</code> values.
For convenience, I also masked out all the irrelevant tokens with <code class="language-plaintext highlighter-rouge">-inf</code> that are not included in the ground truth and also set their relevant class to -1 and set <code class="language-plaintext highlighter-rouge">ignore_index = -1</code> accordingly.
Here’s a sample mask:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">tensor([[0., 0., -inf, -inf, -inf, -inf],
        [0., 0., -inf, -inf, -inf, -inf],
        [-inf, -inf, -inf, -inf, -inf, -inf],
        [-inf, -inf, -inf, -inf, -inf, -inf],
        [-inf, -inf, -inf, -inf, -inf, -inf]])
</span></code></pre></div></div>

<p>I started training my model and the loss was a reasonable float value on the first step, but became <code class="language-plaintext highlighter-rouge">nan</code> in the second step.
This prompted my deep dive.
The TLDR here is that in the example mask above, you can mask the first two columns with <code class="language-plaintext highlighter-rouge">-inf</code> as that’s what you want, but from the third column onwards, mask with 0.</p>

<h2 id="a-simple-example">A Simple Example</h2>

<p>We start with a basic example.
We first create an input tensor and a target tensor.
We enable gradients for the input tensor and set the <code class="language-plaintext highlighter-rouge">ignore_index</code> to -1 as an argument for the <code class="language-plaintext highlighter-rouge">CrossEntropyLoss</code>.
After computing the loss, we perform a backward pass and print the gradients:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="c1"># Define the input tensor and target tensor
</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">input_tensor</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">target_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># Assuming ignore_index is -1
</span>
<span class="c1"># Create the CrossEntropyLoss criterion with ignore_index
</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Compute the loss
</span>
<span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">)</span>

<span class="c1"># Print the loss
</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Loss:</span><span class="sh">"</span><span class="p">,</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>

<span class="c1"># Perform the backward pass
</span>
<span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>

<span class="c1"># Print the gradients
</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Gradients:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">Output:
Loss: 1.6094379425048828
Gradients:
tensor([[0.1000, -0.4000,  0.1000,  0.1000,  0.1000],
        [ 0.1000,  0.1000, -0.4000,  0.1000,  0.1000],
        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])
</span></code></pre></div></div>

<p>Observe here that the gradients are indeed 0 for the third row, as the <code class="language-plaintext highlighter-rouge">target_tensor</code> has <code class="language-plaintext highlighter-rouge">-1</code> as the third element (or second if 0-indexing).
Naturally, if the gradient is zero, then you don’t do any update on the weights, so this is what we want.</p>

<h2 id="what-happens-when-there-are--infs">What happens when there are <code class="language-plaintext highlighter-rouge">-infs</code>?</h2>

<p>Using the same example above, we now explore what happens when we set an entire row to <code class="language-plaintext highlighter-rouge">-inf</code>.
Specifically, this line was added <code class="language-plaintext highlighter-rouge">input_tensor[-1] = float('-inf')</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="c1"># Define the input tensor and target tensor
</span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">input_tensor</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="sh">'</span><span class="s">-inf</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># Note this is added!
</span><span class="n">input_tensor</span><span class="p">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">target_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># Assuming ignore_index is -1
</span>
<span class="c1"># Create the CrossEntropyLoss criterion with ignore_index
</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Compute the loss
</span><span class="n">loss</span> <span class="o">=</span> <span class="nf">criterion</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_tensor</span><span class="p">)</span>

<span class="c1"># Print the loss
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Loss:</span><span class="sh">"</span><span class="p">,</span> <span class="n">loss</span><span class="p">.</span><span class="nf">item</span><span class="p">())</span>

<span class="c1"># Perform the backward pass
</span><span class="n">loss</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>

<span class="c1"># Print the gradients
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Gradients:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">Output:
Loss: 1.6094379425048828
Gradients:
tensor([[0.1000, -0.4000,  0.1000,  0.1000,  0.1000],
        [ 0.1000,  0.1000, -0.4000,  0.1000,  0.1000],
        [    nan,     nan,     nan,     nan,     nan]])
</span></code></pre></div></div>

<p>Observe now that the entire third row contains <code class="language-plaintext highlighter-rouge">nan</code> values, which is the cause of our entire problem.</p>

<h2 id="how-can-i-debug-this-in-reality">How can I debug this in reality?</h2>

<p>I read the PyTorch forums and the best way to debug <code class="language-plaintext highlighter-rouge">nan</code> values in loss is perhaps to start by adding <code class="language-plaintext highlighter-rouge">torch.autograd.anomaly_mode.set_detect_anomaly(True)</code> at the top of your script.
After adding that, I immediately saw that the error was:</p>

<div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="go">RuntimeError: Function 'LogSoftmaxBackward0' returned nan values in its 0th output.
</span></code></pre></div></div>

<p>which suggested that I had an issue with my gradients.
That led me to my deep dive and a better understanding of how <code class="language-plaintext highlighter-rouge">ignore_index</code> is used and this blog post.</p>]]></content><author><name></name></author><category term="code" /><summary type="html"><![CDATA[A deep dive into ignore index and how it affects the gradients.]]></summary></entry></feed>